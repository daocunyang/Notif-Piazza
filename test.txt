mp5 due date- april 30 or may 1?
On the instructions PDF it says due April 30.
However, the piazza says may 1
Also, the deadline on compass2g is May 1. I would assume it is May 1.
It is not time-consuming at all. just run the command and record the stdout
Take May 1 since that is the due date on compass.
We&#39;ll use the deadline on compass, which is May 1
Question about bigram in MP5
For Mp5, if I simply change ngram from 1 to 2  in config.toml, 
will the model only analyze bigram with no considering on unigram anymore?
This is correct. In some sense, bigram contains some information about unigram.
I solved already by adding another column of analyzer consisting ngram=2 inside config.toml
Reached an accuracy of 90.9%, don&#39;t know if it is correct
:) Interesting, don&#39;t know if the metapy just picks the first one, or pick both of them. That would be unigram &#43; bigram.
you can find more about meta configuration here: https://meta-toolkit.org/analyzers-filters-tutorial.html

As is stated in the instruction, &#34;to also use bigrams instead of purely unigram words&#34;, so you are supposed to use both unigram and bigrams here.
I see, so would you want us to use bigram only or bigram &#43; unigram?
same question
yes
wait, which one is it?
both. please refer to the answer above and read the instruction carefully
What is fold in support vector machine?
after the video, still not very clear.
Could you elaborate? 
Yeah, sure. It&#39;s actually about MP5. If I understand correctly, 5-fold cross validation means, we will divide the data into 5 parts, and use four of them to train, left one to test
But does the number 5 or 10 really matter when testing model?
It essentially adds randomness into the trading data and testing data. 
But does 10-fold always give higher accuracy than 5-fold?
even though in MP, I got higher accuracy for 10-fold
Yes and No. the whole idea is randomly shuffle the data, so you don&#39;t overfit your training model, which supposes to do better when doing testing.   If 5-fold is random enough, 10-fold is not necessary.   10 fold trains five more times than 5 fold, supposedly adding more randomness, but not always. It also increases training time, this is your trade off.
Umm, so you are saying that if you increase to 10 fold, the accuracy has high change to increase, however we may might overfitting problems as a result of the increase. is that correct?
The whole point of crossing foldering is to a better model that does not overfit.Cross fold is a tuning method, can be used in knn, randomforest, all the machine learning methods you can think of.If you are interested in this topic, for your reference a good book on machine learning from statistics point of view is called: the elements of statistical learning,    From. Bayesian approach, a good book: pattern recognition and machine learning.      
Okay, I will check it out! Thank you!
Yes, that&#39;s what it means.  It usually uses random shuffle to do it. But in this mp(not confirmed), it seems to use finds sampling to sample the data.
Gibbs sampling typo:)
